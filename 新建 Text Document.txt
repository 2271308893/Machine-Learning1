import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import random
import matplotlib.pyplot as plt
import time

# 设置图片目录
man_dir = 'F:/mssb/faces/man'  # 男性图片目录
woman_dir = 'F:/mssb/faces/woman'  # 女性图片目录


# 随机抽取数据（确保训练集和测试集完全独立）
def sample_images_from_directory(directory, label, num_samples, already_used_files=[]):
    """从指定目录中随机抽取num_samples数量的图片，返回图片和标签，同时避免重复"""
    images = []
    labels = []
    all_images = [f for f in os.listdir(directory) if f.endswith('.jpg') and f not in already_used_files]
    num_samples = min(num_samples, len(all_images))
    sampled_files = random.sample(all_images, num_samples)

    for filename in sampled_files:
        image_path = os.path.join(directory, filename)
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is not None:
            # 将图像调整为固定尺寸（例如128x64）
            image_resized = cv2.resize(image, (128, 64))
            images.append(image_resized)
            labels.append(label)
    return images, labels, sampled_files


# 抽取男性和女性的训练数据（确保训练和测试集不重复）
num_train_samples_man = 3000  # 男性训练样本数
num_train_samples_woman = 3000  # 女性训练样本数

# 保证从训练集目录中抽取，不会出现重复数据
train_man_images, train_man_labels, used_man_files = sample_images_from_directory(man_dir, label=0,
                                                                                  num_samples=num_train_samples_man)
train_woman_images, train_woman_labels, used_woman_files = sample_images_from_directory(woman_dir, label=1,
                                                                                        num_samples=num_train_samples_woman)

# 合并训练集
X_train = train_man_images + train_woman_images
y_train = train_man_labels + train_woman_labels

# 增大测试集至至少200个样本，确保不从训练集目录中抽样
num_test_samples_man = 200  # 男性测试样本数
num_test_samples_woman = 200  # 女性测试样本数

# 从测试目录中抽取数据，确保不和训练集数据重复
test_man_images, test_man_labels, _ = sample_images_from_directory(man_dir, label=0, num_samples=num_test_samples_man,
                                                                   already_used_files=used_man_files)
test_woman_images, test_woman_labels, _ = sample_images_from_directory(woman_dir, label=1,
                                                                       num_samples=num_test_samples_woman,
                                                                       already_used_files=used_woman_files)

# 合并测试集
X_test = test_man_images + test_woman_images
y_test = test_man_labels + test_woman_labels


# 特征提取：将图像展平成一维数组，适合用于PCA处理
def flatten_image(image):
    return image.flatten()


# 将训练集和测试集的图像展平为一维数组
X_train_flattened = [flatten_image(image) for image in X_train]
X_test_flattened = [flatten_image(image) for image in X_test]

# 数据标准化：使用标准化Scaler将数据转换为均值为0，标准差为1
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_flattened)
X_test_scaled = scaler.transform(X_test_flattened)

# PCA降维：减少维度以提高计算效率和准确率
pca = PCA(n_components=100)  # 设置降维后的维度
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# 数据拆分（如果需要重新拆分训练集和验证集）
X_train_pca, X_val_pca, y_train, y_val = train_test_split(X_train_pca, y_train, test_size=0.2, random_state=42)

# 列出需要使用的模型和其名称
classifiers = [
    ('SVM', SVC(kernel='rbf', C=1, gamma='scale')),  # 支持向量机
    (
    'Decision Tree', DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1)),
    # 决策树
    (
    'Random Forest', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1)),
    # 随机森林
    ('KNN', KNeighborsClassifier(n_neighbors=3, weights='uniform', metric='euclidean')),  # K最近邻
    ('Logistic Regression', LogisticRegression(C=1.0, max_iter=1000, solver='lbfgs')),  # 逻辑回归
    ('Naive Bayes', GaussianNB(var_smoothing=1e-9))  # 朴素贝叶斯
]
# 训练并评估每个模型
for model_name, classifier in classifiers:
    print(f"\nTraining and evaluating {model_name}...")

    # 记录开始时间，计算模型训练的时间复杂度
    start_time = time.time()

    # 训练模型
    classifier.fit(X_train_pca, y_train)

    # 记录训练时间
    end_time = time.time()
    training_time = end_time - start_time
    print(f"{model_name} Model training time: {training_time:.2f} seconds")

    # 预测测试集
    y_pred = classifier.predict(X_test_pca)

    # 评估模型
    accuracy = accuracy_score(y_test, y_pred)
    misclassification_rate = 1 - accuracy  # 错分率
    print(f"{model_name} Model accuracy: {accuracy:.2f}")
    print(f"{model_name} Misclassification rate: {misclassification_rate:.2f}")

    # AUC评估（针对二分类问题）
    y_test_bin = [1 if label == 1 else 0 for label in y_test]  # 将标签转为二分类形式
    y_pred_prob = classifier.decision_function(X_test_pca) if hasattr(classifier,
                                                                      'decision_function') else classifier.predict_proba(
        X_test_pca)[:, 1]  # 获取模型的决策值或概率
    auc = roc_auc_score(y_test_bin, y_pred_prob)
    print(f"{model_name} AUC: {auc:.2f}")

    # K折交叉验证
    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5折交叉验证
    cv_scores = cross_val_score(classifier, X_train_pca, y_train, cv=kf, scoring='accuracy')
    print(f"{model_name} K-Fold Cross Validation accuracy: {cv_scores.mean():.2f}")

    # 混淆矩阵
    cm = confusion_matrix(y_test, y_pred)
    print(f"{model_name} Confusion Matrix:")
    print(cm)

    # 分类报告
    print(f"{model_name} Classification Report:")
    print(classification_report(y_test, y_pred))


    # 可视化混淆矩阵
    def plot_confusion_matrix(cm, labels):
        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title(f'{model_name} Confusion Matrix')
        plt.colorbar()
        tick_marks = np.arange(len(labels))
        plt.xticks(tick_marks, labels, rotation=45)
        plt.yticks(tick_marks, labels)
        plt.ylabel('True label')
        plt.xlabel('Predicted label')
        plt.tight_layout()


    labels = ['Man', 'Woman']  # 男性和女性
    plot_confusion_matrix(cm, labels)
    plt.show()
